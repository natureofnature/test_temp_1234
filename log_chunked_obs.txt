INFO 09-15 10:32:39 [__init__.py:36] Available plugins for group vllm.platform_plugins:
INFO 09-15 10:32:39 [__init__.py:38] - ascend -> vllm_ascend:register
INFO 09-15 10:32:39 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 09-15 10:32:39 [__init__.py:232] Platform plugin ascend is activated
WARNING 09-15 10:32:40 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
INFO 09-15 10:32:41 [importing.py:63] Triton not installed or not compatible; certain GPU-related functions will not be available.
WARNING 09-15 10:32:41 [registry.py:477] Model architecture DeepSeekMTPModel is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_mtp:CustomDeepSeekMTP.
WARNING 09-15 10:32:41 [registry.py:477] Model architecture Qwen2VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_vl:AscendQwen2VLForConditionalGeneration.
WARNING 09-15 10:32:41 [registry.py:477] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl:AscendQwen2_5_VLForConditionalGeneration.
WARNING 09-15 10:32:41 [registry.py:477] Model architecture DeepseekV2ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_v2:CustomDeepseekV2ForCausalLM.
WARNING 09-15 10:32:41 [registry.py:477] Model architecture DeepseekV3ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_v3:CustomDeepseekV3ForCausalLM.
WARNING 09-15 10:32:41 [registry.py:477] Model architecture Qwen3MoeForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3_moe:CustomQwen3MoeForCausalLM.
WARNING 09-15 10:32:41 [registry.py:477] Model architecture Qwen3ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3:CustomQwen3ForCausalLM.
INFO 09-15 10:32:41 [utils.py:328] non-default args: {'trust_remote_code': True, 'max_model_len': 4096, 'tensor_parallel_size': 2, 'context_parallel_size': 4, 'enable_sequence_parallel': True, 'enable_expert_parallel': True, 'block_size': 128, 'enable_prefix_caching': False, 'max_num_batched_tokens': 1024, 'disable_log_stats': True, 'enforce_eager': True, 'enable_chunked_prefill': True, 'additional_config': {'ascend_scheduler_config': {'enabled': True}}, 'model': '/home/DeepSeek-V2-Lite'}
INFO 09-15 10:32:41 [config.py:234] Replacing legacy 'type' key with 'rope_type'
INFO 09-15 10:32:48 [__init__.py:744] Resolved architecture: DeepseekV2ForCausalLM
INFO 09-15 10:32:48 [__init__.py:1773] Using max model len 4096
INFO 09-15 10:32:48 [config.py:234] Replacing legacy 'type' key with 'rope_type'
INFO 09-15 10:32:48 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=1024.
INFO 09-15 10:32:48 [platform.py:144] Compilation disabled, using eager mode by default
WARNING 09-15 10:32:48 [platform.py:162] compilation_config.level = CompilationLevel.NO_COMPILATION is set, Setting CUDAGraphMode to NONE
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:32:49 [core.py:648] Waiting for init message from front-end.
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:32:49 [core.py:75] Initializing a V1 LLM engine (v0.1.dev9077+g05579c458) with config: model='/home/DeepSeek-V2-Lite', speculative_config=None, tokenizer='/home/DeepSeek-V2-Lite', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=npu, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/DeepSeek-V2-Lite, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":["all"],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_0 pid=976594)[0;0m WARNING 09-15 10:32:49 [multiproc_worker_utils.py:273] Reducing Torch parallelism from 640 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:32:49 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3, 4, 5, 6, 7], buffer_handle=(8, 16777216, 10, 'psm_34ac044a'), local_subscribe_addr='ipc:///tmp/5b3f1291-b64b-40b8-87c4-289d4d6c1870', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:32:59 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_aa22b440'), local_subscribe_addr='ipc:///tmp/fd4f09e3-6a1b-4bc4-9bba-531af7699b7b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:00 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_453ffa05'), local_subscribe_addr='ipc:///tmp/98162252-b431-4b7d-b170-e07b2a34dc35', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:01 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_27b6ef5c'), local_subscribe_addr='ipc:///tmp/655e3930-40c3-47be-b457-18bdb14b73de', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:02 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_19ae06b9'), local_subscribe_addr='ipc:///tmp/def8222a-2c18-4fba-b4d1-ba0778a1ff46', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:03 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_fc979109'), local_subscribe_addr='ipc:///tmp/e5f84994-657f-4e06-82c5-73db78ee464f', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:03 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_71d0e614'), local_subscribe_addr='ipc:///tmp/607766b7-287f-4f0c-b670-a6f1c3067509', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:03 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_a6e0bc9d'), local_subscribe_addr='ipc:///tmp/09588cb9-2b69-47e1-88d1-169da58c90c2', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:03 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_7c35d481'), local_subscribe_addr='ipc:///tmp/f0619de5-f691-4475-b8ae-b06a3d68404f', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:10 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_211e3a9b'), local_subscribe_addr='ipc:///tmp/d71abf90-2869-4b9d-ad8e-03ca4d9522e2', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:10 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_5a05b1b2'), local_subscribe_addr='ipc:///tmp/1502a8f5-8a7e-45a6-aaa8-a19b963e7395', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:10 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_53f101c3'), local_subscribe_addr='ipc:///tmp/428fd396-8e92-4b72-9f7c-5cacd109456b', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:10 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_828f5ad9'), local_subscribe_addr='ipc:///tmp/bc8d8f53-d31f-4080-9dea-5b3ee8fddee8', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:10 [parallel_state.py:1163] rank 7 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 7, CP rank 3
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:10 [parallel_state.py:1163] rank 5 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 5, CP rank 2
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:10 [parallel_state.py:1163] rank 1 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1, CP rank 0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:10 [parallel_state.py:1163] rank 3 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 3, CP rank 1
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:10 [parallel_state.py:1163] rank 2 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 2, CP rank 1
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:10 [parallel_state.py:1163] rank 0 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0, CP rank 0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:10 [parallel_state.py:1163] rank 4 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 4, CP rank 2
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:10 [parallel_state.py:1163] rank 6 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 6, CP rank 3
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:10 [model_runner_v1.py:2630] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:10 [model_runner_v1.py:2630] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:10 [model_runner_v1.py:2630] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:10 [model_runner_v1.py:2630] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:10 [model_runner_v1.py:2630] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:10 [model_runner_v1.py:2630] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:10 [model_runner_v1.py:2630] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:10 [model_runner_v1.py:2630] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:11 [layer.py:845] [EP Rank 0/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:11 [layer.py:845] [EP Rank 6/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:11 [layer.py:845] [EP Rank 2/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:11 [layer.py:845] [EP Rank 7/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:11 [layer.py:845] [EP Rank 4/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:11 [layer.py:845] [EP Rank 3/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:11 [layer.py:845] [EP Rank 1/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:11 [layer.py:845] [EP Rank 5/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:14 [default_loader.py:267] Loading weights took 2.53 seconds
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:14 [default_loader.py:267] Loading weights took 2.38 seconds
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:14 [default_loader.py:267] Loading weights took 2.49 seconds
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:14 [default_loader.py:267] Loading weights took 2.48 seconds
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:14 [default_loader.py:267] Loading weights took 2.49 seconds
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:14 [default_loader.py:267] Loading weights took 2.48 seconds
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:14 [default_loader.py:267] Loading weights took 2.53 seconds
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:14 [default_loader.py:267] Loading weights took 2.71 seconds
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:15 [model_runner_v1.py:2660] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:15 [model_runner_v1.py:2660] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:15 [model_runner_v1.py:2660] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:15 [model_runner_v1.py:2660] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:15 [model_runner_v1.py:2660] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:15 [model_runner_v1.py:2660] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:15 [model_runner_v1.py:2660] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:16 [model_runner_v1.py:2660] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:16 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:17 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:17 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:17 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:17 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:17 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:17 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:17 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:17 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:17 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:20 [worker_v1.py:190] Available memory: 51680979968, total memory: 65787658240
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:20 [worker_v1.py:190] Available memory: 51680159744, total memory: 65787658240
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:20 [worker_v1.py:190] Available memory: 51927769907, total memory: 65796046848
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:20 [worker_v1.py:190] Available memory: 51670827008, total memory: 65787658240
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:20 [worker_v1.py:190] Available memory: 51939396403, total memory: 65796046848
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:20 [worker_v1.py:190] Available memory: 51206176768, total memory: 65787658240
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:20 [worker_v1.py:190] Available memory: 51925434163, total memory: 65796046848
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:20 [worker_v1.py:190] Available memory: 51929758515, total memory: 65796046848
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:850] GPU KV cache size: 1,646,208 tokens
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3215.25x
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:850] GPU KV cache size: 1,669,376 tokens
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3260.50x
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:850] GPU KV cache size: 1,661,184 tokens
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3244.50x
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:850] GPU KV cache size: 1,669,760 tokens
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3261.25x
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:850] GPU KV cache size: 1,661,440 tokens
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3245.00x
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:850] GPU KV cache size: 1,669,504 tokens
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3260.75x
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:850] GPU KV cache size: 1,661,440 tokens
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3245.00x
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:850] GPU KV cache size: 1,669,376 tokens
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3260.50x
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [core.py:217] init engine (profile, create kv cache, warmup model) took 4.26 seconds
[1;36m(EngineCore_0 pid=976594)[0;0m WARNING 09-15 10:33:20 [core.py:110] Using configured V1 scheduler class vllm_ascend.core.scheduler.AscendScheduler. This scheduler interface is not public and compatibility may not be maintained.
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:20 [platform.py:144] Compilation disabled, using eager mode by default
[1;36m(EngineCore_0 pid=976594)[0;0m WARNING 09-15 10:33:20 [platform.py:162] compilation_config.level = CompilationLevel.NO_COMPILATION is set, Setting CUDAGraphMode to NONE
INFO 09-15 10:33:20 [llm.py:285] Supported_tasks: ['generate']
INFO 09-15 10:33:20 [__init__.py:36] No IOProcessor plugins requested by the model
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:21 [scheduler.py:180] ======> [SCH-PREFILL] req=0 chunk step_tokens=1024 cp=4 sp=2 num_blocks_of_cp_sp.shape=(4, 2) token_budget_left=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1196] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1196] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1196] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1196] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1196] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1196] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1196] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1196] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1323] ===> seq_lens_np:[256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1323] ===> seq_lens_np:[256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1323] ===> seq_lens_np:[256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1323] ===> seq_lens_np:[256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1323] ===> seq_lens_np:[256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1323] ===> seq_lens_np:[256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1323] ===> seq_lens_np:[256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1323] ===> seq_lens_np:[256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1105]   [256 256]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:1, prev_compuated_total:0, cum_for_rank:256, num_new_tokens_rank:256, num_scheduled_tokens_for_slot:[1024],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:2, prev_compuated_total:0, cum_for_rank:256, num_new_tokens_rank:256, num_scheduled_tokens_for_slot:[1024],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:1, prev_compuated_total:0, cum_for_rank:256, num_new_tokens_rank:256, num_scheduled_tokens_for_slot:[1024],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:3, prev_compuated_total:0, cum_for_rank:256, num_new_tokens_rank:256, num_scheduled_tokens_for_slot:[1024],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:2, prev_compuated_total:0, cum_for_rank:256, num_new_tokens_rank:256, num_scheduled_tokens_for_slot:[1024],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:0, prev_compuated_total:0, cum_for_rank:256, num_new_tokens_rank:256, num_scheduled_tokens_for_slot:[1024],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:3, prev_compuated_total:0, cum_for_rank:256, num_new_tokens_rank:256, num_scheduled_tokens_for_slot:[1024],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:0, prev_compuated_total:0, cum_for_rank:256, num_new_tokens_rank:256, num_scheduled_tokens_for_slot:[1024],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130] ===> slot mapping prefill rank > 0, cp rank:1, absolute_start_pos:0, positions_for_slot_abs:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  252 253 254 255], block_offsets:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  124 125 126 127],slot_mapping:tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         380, 381, 382, 383], dtype=torch.int32),  block table size:128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130] ===> slot mapping prefill rank > 0, cp rank:2, absolute_start_pos:0, positions_for_slot_abs:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  252 253 254 255], block_offsets:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  124 125 126 127],slot_mapping:tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130] ===> slot mapping prefill rank > 0, cp rank:1, absolute_start_pos:0, positions_for_slot_abs:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  252 253 254 255], block_offsets:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  124 125 126 127],slot_mapping:tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         380, 381, 382, 383], dtype=torch.int32),  block table size:128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         380, 381, 382, 383], dtype=torch.int32),  block table size:128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130] ===> slot mapping prefill rank > 0, cp rank:2, absolute_start_pos:0, positions_for_slot_abs:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  252 253 254 255], block_offsets:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  124 125 126 127],slot_mapping:tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130] ===> slot mapping prefill rank > 0, cp rank:3, absolute_start_pos:0, positions_for_slot_abs:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  252 253 254 255], block_offsets:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  124 125 126 127],slot_mapping:tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130] ===> slot mapping prefill rank > 0, cp rank:0, absolute_start_pos:0, positions_for_slot_abs:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  252 253 254 255], block_offsets:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  124 125 126 127],slot_mapping:tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         380, 381, 382, 383], dtype=torch.int32),  block table size:128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         380, 381, 382, 383], dtype=torch.int32),  block table size:128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130] ===> slot mapping prefill rank > 0, cp rank:0, absolute_start_pos:0, positions_for_slot_abs:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  252 253 254 255], block_offsets:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  124 125 126 127],slot_mapping:tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130] ===> slot mapping prefill rank > 0, cp rank:3, absolute_start_pos:0, positions_for_slot_abs:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  252 253 254 255], block_offsets:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  126 127   0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]   88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]  124 125 126 127],slot_mapping:tensor([128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         380, 381, 382, 383], dtype=torch.int32),  block table size:128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         380, 381, 382, 383], dtype=torch.int32),  block table size:128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1130]         380, 381, 382, 383], dtype=torch.int32),  block table size:128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([  0, 256], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([  0, 256], dtype=torch.int32),seq_lens_cpu:tensor([256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([  0, 256], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([  0, 256], dtype=torch.int32),seq_lens_cpu:tensor([256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([  0, 256], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([  0, 256], dtype=torch.int32),seq_lens_cpu:tensor([256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0], dtype=torch.int32), num_actual_tokens:256, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0], dtype=torch.int32), num_actual_tokens:256, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0], dtype=torch.int32), num_actual_tokens:256, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([  0, 256], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([  0, 256], dtype=torch.int32),seq_lens_cpu:tensor([256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0], dtype=torch.int32), num_actual_tokens:256, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([  0, 256], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([  0, 256], dtype=torch.int32),seq_lens_cpu:tensor([256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0], dtype=torch.int32), num_actual_tokens:256, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([  0, 256], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([  0, 256], dtype=torch.int32),seq_lens_cpu:tensor([256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0], dtype=torch.int32), num_actual_tokens:256, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([  0, 256], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([  0, 256], dtype=torch.int32),seq_lens_cpu:tensor([256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [mla_v1.py:367] --->seq_lens:tensor([256], dtype=torch.int32), query_lens:tensor([256], dtype=torch.int32), num_computed_tokens_cpu:tensor([0], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [mla_v1.py:367] --->seq_lens:tensor([256], dtype=torch.int32), query_lens:tensor([256], dtype=torch.int32), num_computed_tokens_cpu:tensor([0], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([  0, 256], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([  0, 256], dtype=torch.int32),seq_lens_cpu:tensor([256,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [mla_v1.py:367] --->seq_lens:tensor([256], dtype=torch.int32), query_lens:tensor([256], dtype=torch.int32), num_computed_tokens_cpu:tensor([0], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0], dtype=torch.int32), num_actual_tokens:256, actual_seq_lengths_q:[]
[1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [model_runner_v1.py:1520]           0,   0,   0,   0], dtype=torch.int32), num_actual_tokens:256, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [mla_v1.py:367] --->seq_lens:tensor([256], dtype=torch.int32), query_lens:tensor([256], dtype=torch.int32), num_computed_tokens_cpu:tensor([0], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [mla_v1.py:367] --->seq_lens:tensor([256], dtype=torch.int32), query_lens:tensor([256], dtype=torch.int32), num_computed_tokens_cpu:tensor([0], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m WARNING 09-15 10:33:21 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m WARNING 09-15 10:33:21 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m WARNING 09-15 10:33:21 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m WARNING 09-15 10:33:21 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [mla_v1.py:367] --->seq_lens:tensor([256], dtype=torch.int32), query_lens:tensor([256], dtype=torch.int32), num_computed_tokens_cpu:tensor([0], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [mla_v1.py:367] --->seq_lens:tensor([256], dtype=torch.int32), query_lens:tensor([256], dtype=torch.int32), num_computed_tokens_cpu:tensor([0], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [mla_v1.py:367] --->seq_lens:tensor([256], dtype=torch.int32), query_lens:tensor([256], dtype=torch.int32), num_computed_tokens_cpu:tensor([0], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:0
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m WARNING 09-15 10:33:21 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m WARNING 09-15 10:33:21 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m WARNING 09-15 10:33:21 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m WARNING 09-15 10:33:21 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp0_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp0_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp0_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp0_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp0_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp0_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp0_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp0_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp1_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp1_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp1_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m ('Warning: torch.save with "_use_new_zipfile_serialization = False" is not recommended for npu tensor, which may bring unexpected errors and hopefully set "_use_new_zipfile_serialization = True"', 'if it is necessary to use this, please convert the npu tensor to cpu tensor for saving')
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp1_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp1_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp1_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp1_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:21 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp1_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:27 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp0_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:27 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:27 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:27 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:27 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:27 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:27 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp0_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:28 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp0_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:28 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp0_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:28 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp0_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:28 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp0_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:28 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp0_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:28 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp0_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:28 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp1_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:28 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:28 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp1_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp1_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp1_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp1_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp1_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp1_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp1_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:29 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([1024, 1, 512]), k_pe shape:torch.Size([1024, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp1_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp0_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp0_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp1_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp0_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp1_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp1_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp0_step0_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp0_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp0_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp1_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp1_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp0_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp1_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp1_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:29 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp0_step0_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp0_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp0_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp0_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp0_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp0_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp0_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp0_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp0_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp1_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp1_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp1_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:36 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp1_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:36 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp1_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp1_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp1_step0_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp1_step0_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([128, 129, 130,  ...,  -1,  -1,  -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([384, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [384]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([128, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [128]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([256, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [256]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([896, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [896]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([512, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [512]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([768, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [768]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([128, 8, 128]), q_rope:torch.Size([128, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([640, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([128, 8, 128]), softmax_lse:torch.Size([8, 128]), seq_len:tensor([[128],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1252]         [640]], dtype=torch.int32),prout shape:torch.Size([128, 8, 128]), prev_lse shape:torch.Size([8, 128]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=976594)[0;0m INFO 09-15 10:33:37 [scheduler.py:372] ======> [SCH-RUNNING] req=0 chunk step_tokens=122 cp=4 sp=2 num_blocks_of_cp_sp.shape=(4, 2) token_budget_left=1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1196] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1196] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1196] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1196] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1196] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1196] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1196] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1196] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1231] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1323] ===> seq_lens_np:[1056]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1323] ===> seq_lens_np:[1056]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1323] ===> seq_lens_np:[1056]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1323] ===> seq_lens_np:[1056]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1323] ===> seq_lens_np:[1056]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[1146 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1323] ===> seq_lens_np:[1056]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1323] ===> seq_lens_np:[1056]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[1146 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[1146 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[1146 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1323] ===> seq_lens_np:[1056]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[1146 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[1146 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[1146 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105] ===> slot mapping prefill cp, num_computed_and_new_tokens_batch:[[[1146 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1105]   [1024 1024]]]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:3, prev_compuated_total:1024, cum_for_rank:1024, num_new_tokens_rank:0, num_scheduled_tokens_for_slot:[128],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:0, prev_compuated_total:1024, cum_for_rank:1146, num_new_tokens_rank:122, num_scheduled_tokens_for_slot:[128],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:1, prev_compuated_total:1024, cum_for_rank:1024, num_new_tokens_rank:0, num_scheduled_tokens_for_slot:[128],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:2, prev_compuated_total:1024, cum_for_rank:1024, num_new_tokens_rank:0, num_scheduled_tokens_for_slot:[128],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:1, prev_compuated_total:1024, cum_for_rank:1024, num_new_tokens_rank:0, num_scheduled_tokens_for_slot:[128],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:3, prev_compuated_total:1024, cum_for_rank:1024, num_new_tokens_rank:0, num_scheduled_tokens_for_slot:[128],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:2, prev_compuated_total:1024, cum_for_rank:1024, num_new_tokens_rank:0, num_scheduled_tokens_for_slot:[128],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114] ===> slot mapping prefill cp, cp rank:0, prev_compuated_total:1024, cum_for_rank:1024, num_new_tokens_rank:0, num_scheduled_tokens_for_slot:[128],block_table_req:tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1114]         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32), block_table_indices:tensor([1, 1, 1,  ..., 0, 0, 0], dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130] ===> slot mapping prefill rank > 0, cp rank:0, absolute_start_pos:1024, positions_for_slot_abs:[1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]  1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]  1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]  1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]  1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]  1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]  1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]  1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]  1136 1137 1138 1139 1140 1141 1142 1143 1144 1145], block_offsets:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]   18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]   36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]   54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]   72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]   90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]  108 109 110 111 112 113 114 115 116 117 118 119 120 121],slot_mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1130]         1272, 1273], dtype=torch.int32),  block table size:128
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1338] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1459] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([ 0, 32], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([ 0, 32], dtype=torch.int32),seq_lens_cpu:tensor([1056,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:32, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([ 0, 32], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([ 0, 32], dtype=torch.int32),seq_lens_cpu:tensor([1056,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:32, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([ 0, 32], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([ 0, 32], dtype=torch.int32),seq_lens_cpu:tensor([1056,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([ 0, 32], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([ 0, 32], dtype=torch.int32),seq_lens_cpu:tensor([1056,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:32, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:32, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([ 0, 32], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([ 0, 32], dtype=torch.int32),seq_lens_cpu:tensor([1056,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([ 0, 32], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([ 0, 32], dtype=torch.int32),seq_lens_cpu:tensor([1056,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([ 0, 32], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([ 0, 32], dtype=torch.int32),seq_lens_cpu:tensor([1056,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:32, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:32, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:32, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:367] --->seq_lens:tensor([1056], dtype=torch.int32), query_lens:tensor([32], dtype=torch.int32), num_computed_tokens_cpu:tensor([1024], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:367] --->seq_lens:tensor([1056], dtype=torch.int32), query_lens:tensor([32], dtype=torch.int32), num_computed_tokens_cpu:tensor([1024], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:367] --->seq_lens:tensor([1056], dtype=torch.int32), query_lens:tensor([32], dtype=torch.int32), num_computed_tokens_cpu:tensor([1024], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:367] --->seq_lens:tensor([1056], dtype=torch.int32), query_lens:tensor([32], dtype=torch.int32), num_computed_tokens_cpu:tensor([1024], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([ 0, 32], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([ 0, 32], dtype=torch.int32),seq_lens_cpu:tensor([1056,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:32, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:367] --->seq_lens:tensor([1056], dtype=torch.int32), query_lens:tensor([32], dtype=torch.int32), num_computed_tokens_cpu:tensor([1024], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:367] --->seq_lens:tensor([1056], dtype=torch.int32), query_lens:tensor([32], dtype=torch.int32), num_computed_tokens_cpu:tensor([1024], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:367] --->seq_lens:tensor([1056], dtype=torch.int32), query_lens:tensor([32], dtype=torch.int32), num_computed_tokens_cpu:tensor([1024], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:367] --->seq_lens:tensor([1056], dtype=torch.int32), query_lens:tensor([32], dtype=torch.int32), num_computed_tokens_cpu:tensor([1024], dtype=torch.int32), reqs_start:0, num_reqs:1, chunked prefill enabled:True, max_context_len_cpu:1024
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp0_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp0_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp0_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp0_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp1_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp1_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp1_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp1_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp0_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp0_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp0_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp0_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp1_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp1_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp1_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:37 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp1_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp0_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp0_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:40 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp0_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp0_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp0_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp1_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp1_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp0_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp1_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp1_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:46 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:46 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp0_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp0_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp0_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp0_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp0_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:46 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp0_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp1_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp1_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp1_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp1_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp2_sp1_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp0_sp1_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp3_sp1_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer0_cp1_sp1_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:1563] [dump info], kv_c_normed shape:torch.Size([128, 1, 512]), k_pe shape:torch.Size([128, 1, 64])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp0_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp0_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp0_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp0_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp1_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp1_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp1_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp1_step1_kv_prefill.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp1_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp1_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp0_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp0_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp0_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp1_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp1_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:47 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp0_step1_kv_prefill_post.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp0_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp0_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:50 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp0_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:55 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp0_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:56 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp1_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp1_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp1_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:56 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp1_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:56 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp0_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:56 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp0_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp1_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp1_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp0_step1_kv_prefill_causal_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp1_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp1_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp1_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp1_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp0_step1_kv_prefill_context_before_mla.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp0_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp3_sp0_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp0_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp1_sp1_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp2_sp1_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:645] [DUMP] wrote debug/compare/layer1_cp0_sp0_step1_attn_prefill_out.pkl
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:0, slot mapping:tensor([1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         1272, 1273,   -1,   -1,   -1,   -1,   -1,   -1], device='npu:0',
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]        dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:0, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:0,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:3,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:1,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548] ====> cp_rank:2,sp_rank:1, slot mapping:tensor([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1548]         -1, -1], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([48, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [48]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([16, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [16]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([32, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [32]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([112, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[ 16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [112]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([64, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [64]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([96, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [96]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252] -->mask_no_mask, q_node:torch.Size([16, 8, 128]), q_rope:torch.Size([16, 8, 64]), k_nope:torch.Size([128, 8, 128]),k_rope:torch.Size([128, 8, 64]),value:torch.Size([80, 8, 128]), mask:torch.Size([512, 512]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([16, 8, 128]), softmax_lse:torch.Size([8, 16]), seq_len:tensor([[16],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1252]         [80]], dtype=torch.int32),prout shape:torch.Size([16, 8, 128]), prev_lse shape:torch.Size([8, 16]) 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:1165] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:0', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:4', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:7', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:0', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:1', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:4', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12861, 128, 1, 512]),cache_k_pe.shape:torch.Size([12861, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:7', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:2', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:6', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:3', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:1', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] ||||||====> mask shape:torch.Size([512, 512]), mask_local: 
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765] tensor([[0., 1., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 1.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 1., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         ...,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 1., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 1.],
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:765]         [0., 0., 0.,  ..., 0., 0., 0.]], device='npu:5', dtype=torch.bfloat16)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13042, 128, 1, 512]),cache_k_pe.shape:torch.Size([13042, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:6', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:2', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:3', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12980, 128, 1, 512]),cache_k_pe.shape:torch.Size([12980, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([12978, 128, 1, 512]),cache_k_pe.shape:torch.Size([12978, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:804] --->here, prefill context start location:tensor([0], device='npu:5', dtype=torch.int32)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:815] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13045, 128, 1, 512]),cache_k_pe.shape:torch.Size([13045, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:822] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:831] --->here, cache_kv_c.shape:torch.Size([13043, 128, 1, 512]),cache_k_pe.shape:torch.Size([13043, 128, 1, 64]), q_node:torch.Size([32, 8, 128]), q_rope:torch.Size([32, 8, 64]), k_nope:torch.Size([1024, 8, 128]),k_rope:torch.Size([1024, 8, 64]),value:torch.Size([1024, 8, 128]), seq_len:torch.Size([2, 1]), head_num:8, kv_head_num:8,qk_scale:0.1147213867929261,out:torch.Size([32, 8, 128]), softmax_lse:torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:899] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:909] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:911] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:913] --->here, out_r shape:torch.Size([32, 8, 128]), lse_r.shape:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:915] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:917] --->here
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:920] --->here, chunk shape:torch.Size([32, 8, 128]),torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:892] ---->here, out shape:torch.Size([32, 8, 128]), lse shape:torch.Size([32, 8, 1]), block_out:torch.Size([32, 8, 128]), block lse:torch.Size([32, 8, 1])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [mla_v1.py:928] #####> [MLA-CTX-CP] it=0 toks=1024 q_nope.shape=torch.Size([32, 8, 128]) k_nope.shape=torch.Size([1024, 8, 128]) v.shape=torch.Size([1024, 8, 128]) out_local.shape=torch.Size([32, 8, 128]) lse_local.shape=torch.Size([8, 32])
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1146, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1147,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1146, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1147,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1146, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1147,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1146, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1147,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1146, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1147,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1146, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1147,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1146, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1147,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1146, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1147,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1147, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1148,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1147, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1148,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1147, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1148,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1147, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1148,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1147, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1148,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1147, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1148,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1147, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1148,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1147, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1148,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1148, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1149,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1148, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1149,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1148, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1149,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1148, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1149,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1148, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1149,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1148, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1149,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1148, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1149,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1148, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1149,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1149, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1149, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1149, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1149, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1149, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1149, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1149, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1149, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1150,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:57 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1150, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1151,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1150, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1151,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1150, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1151,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1150, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1151,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1150, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1151,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1150, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1151,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1150, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1151,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1150, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1151,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1151, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1152,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1151, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1152,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1151, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1152,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1151, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1152,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1151, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1152,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1151, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1152,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1151, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1152,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1151, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1152,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1152, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1153,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1152, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1153,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1152, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1153,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1152, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1153,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1152, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1153,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1152, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1153,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1152, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1153,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1152, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1153,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1153, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1154,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1153, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1154,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1153, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1154,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1153, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1154,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1153, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1154,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1153, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1154,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1153, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1154,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1153, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1154,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1196] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1330] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=(1,)
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1344] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1154, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:0', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1155,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1154, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:4', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1155,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1154, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:3', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1155,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1154, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:7', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1155,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1154, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:2', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1155,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1154, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:5', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1155,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1154, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:6', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1155,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520] ======> attentin metadata==> positions: [1154, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], query_start_loc:tensor([0, 1], device='npu:1', dtype=torch.int32), query_start_loc_cpu:tensor([0, 1], dtype=torch.int32),seq_lens_cpu:tensor([1155,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [model_runner_v1.py:1520]            0,    0,    0,    0], dtype=torch.int32), num_actual_tokens:1, actual_seq_lengths_q:[]
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976621)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976601)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976636)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976611)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976616)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976626)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1016] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP0 pid=976631)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:1021] =====> kv cache is None
[1;36m(EngineCore_0 pid=976594)[0;0m [1;36m(VllmWorker TP1 pid=976606)[0;0m INFO 09-15 10:33:58 [deepseek_v2.py:833] called in forward in CustomDeepseekV2Model with none attn meta
TTFT: 38051.26905441284 ms
req_num: 0
[['593', '595', '597', '599', '']] -> Generated text: '5555555555'
Token ids: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20]

end.
ERROR 09-15 10:34:00 [core_client.py:562] Engine core proc EngineCore_0 died unexpectedly, shutting down client.
