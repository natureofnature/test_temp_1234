INFO 09-10 17:13:48 [__init__.py:36] Available plugins for group vllm.platform_plugins:
INFO 09-10 17:13:48 [__init__.py:38] - ascend -> vllm_ascend:register
INFO 09-10 17:13:48 [__init__.py:41] All plugins in this group will be loaded. Set `VLLM_PLUGINS` to control which plugins to load.
INFO 09-10 17:13:48 [__init__.py:232] Platform plugin ascend is activated
WARNING 09-10 17:13:49 [_custom_ops.py:20] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
INFO 09-10 17:13:50 [importing.py:63] Triton not installed or not compatible; certain GPU-related functions will not be available.
WARNING 09-10 17:13:50 [registry.py:477] Model architecture DeepSeekMTPModel is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_mtp:CustomDeepSeekMTP.
WARNING 09-10 17:13:50 [registry.py:477] Model architecture Qwen2VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_vl:AscendQwen2VLForConditionalGeneration.
WARNING 09-10 17:13:50 [registry.py:477] Model architecture Qwen2_5_VLForConditionalGeneration is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen2_5_vl:AscendQwen2_5_VLForConditionalGeneration.
WARNING 09-10 17:13:50 [registry.py:477] Model architecture DeepseekV2ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_v2:CustomDeepseekV2ForCausalLM.
WARNING 09-10 17:13:50 [registry.py:477] Model architecture DeepseekV3ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.deepseek_v3:CustomDeepseekV3ForCausalLM.
WARNING 09-10 17:13:50 [registry.py:477] Model architecture Qwen3MoeForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3_moe:CustomQwen3MoeForCausalLM.
WARNING 09-10 17:13:50 [registry.py:477] Model architecture Qwen3ForCausalLM is already registered, and will be overwritten by the new model class vllm_ascend.models.qwen3:CustomQwen3ForCausalLM.
INFO 09-10 17:13:50 [utils.py:328] non-default args: {'trust_remote_code': True, 'max_model_len': 4096, 'tensor_parallel_size': 2, 'context_parallel_size': 4, 'enable_sequence_parallel': True, 'enable_expert_parallel': True, 'block_size': 128, 'enable_prefix_caching': False, 'max_num_batched_tokens': 1024, 'disable_log_stats': True, 'enforce_eager': True, 'enable_chunked_prefill': True, 'additional_config': {'ascend_scheduler_config': {'enabled': True}}, 'model': '/home/DeepSeek-V2-Lite'}
INFO 09-10 17:13:50 [config.py:234] Replacing legacy 'type' key with 'rope_type'
INFO 09-10 17:13:58 [__init__.py:744] Resolved architecture: DeepseekV2ForCausalLM
INFO 09-10 17:13:58 [__init__.py:1773] Using max model len 4096
INFO 09-10 17:13:58 [config.py:234] Replacing legacy 'type' key with 'rope_type'
INFO 09-10 17:13:58 [scheduler.py:226] Chunked prefill is enabled with max_num_batched_tokens=1024.
INFO 09-10 17:13:58 [platform.py:144] Compilation disabled, using eager mode by default
WARNING 09-10 17:13:58 [platform.py:162] compilation_config.level = CompilationLevel.NO_COMPILATION is set, Setting CUDAGraphMode to NONE
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:13:58 [core.py:648] Waiting for init message from front-end.
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:13:58 [core.py:75] Initializing a V1 LLM engine (v0.1.dev9077+g05579c458) with config: model='/home/DeepSeek-V2-Lite', speculative_config=None, tokenizer='/home/DeepSeek-V2-Lite', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=auto, device_config=npu, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/home/DeepSeek-V2-Lite, enable_prefix_caching=False, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={"level":0,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":["all"],"splitting_ops":null,"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":0,"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"pass_config":{},"max_capture_size":0,"local_cache_dir":null}
[1;36m(EngineCore_0 pid=215225)[0;0m WARNING 09-10 17:13:58 [multiproc_worker_utils.py:273] Reducing Torch parallelism from 640 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:13:58 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0, 1, 2, 3, 4, 5, 6, 7], buffer_handle=(8, 16777216, 10, 'psm_fd23375d'), local_subscribe_addr='ipc:///tmp/a787b5f7-d5a0-4d8f-b6dc-dc97cf57af67', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:09 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1f8b4c4d'), local_subscribe_addr='ipc:///tmp/190636c4-29b9-46b4-b1fe-891991c69ad8', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:10 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_aa6526ec'), local_subscribe_addr='ipc:///tmp/9d642339-d399-4555-b022-00241b6109d6', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:10 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_1762f516'), local_subscribe_addr='ipc:///tmp/5b75bea5-2116-437f-9a8a-93fdd310da93', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:12 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_5e304ede'), local_subscribe_addr='ipc:///tmp/2a1b1d86-aec2-4cdf-b22d-7350ae2c5fc4', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:13 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_bff11c25'), local_subscribe_addr='ipc:///tmp/e7424b5b-3ec0-4712-989e-730331aa5123', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:13 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_87a5dfb2'), local_subscribe_addr='ipc:///tmp/d1ba6575-0b01-421c-81bd-bf3937ef2a88', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:14 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_f209c186'), local_subscribe_addr='ipc:///tmp/a129c4b6-7e23-4cbf-846c-43d6cba786a1', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:14 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[0], buffer_handle=(1, 10485760, 10, 'psm_8c352006'), local_subscribe_addr='ipc:///tmp/31343feb-6e8d-4476-b9f1-533568b3fa49', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:21 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_8fc178dc'), local_subscribe_addr='ipc:///tmp/4d45bfd4-7ce5-46ee-8c48-c46e9201f5d0', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:21 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_f463d0b3'), local_subscribe_addr='ipc:///tmp/2cc7866c-a3a8-4ce4-a3a0-20238e7ebb30', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:21 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_3f87841e'), local_subscribe_addr='ipc:///tmp/fab7e2f3-b92f-4e82-a96c-f141b52d7ce9', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:21 [shm_broadcast.py:289] vLLM message queue communication handle: Handle(local_reader_ranks=[1], buffer_handle=(1, 4194304, 6, 'psm_baffc1d5'), local_subscribe_addr='ipc:///tmp/31fb3c5b-ae18-428d-a2ec-04968c147904', remote_subscribe_addr=None, remote_addr_ipv6=False)
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:21 [parallel_state.py:1163] rank 6 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 6, CP rank 3
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:21 [parallel_state.py:1163] rank 0 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0, CP rank 0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:21 [parallel_state.py:1163] rank 4 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 4, CP rank 2
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:21 [parallel_state.py:1163] rank 2 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 2, CP rank 1
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:21 [parallel_state.py:1163] rank 1 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 1, CP rank 0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:21 [parallel_state.py:1163] rank 3 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 3, CP rank 1
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:21 [parallel_state.py:1163] rank 5 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 5, CP rank 2
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:21 [parallel_state.py:1163] rank 7 in world size 8 is assigned as DP rank 0, PP rank 0, TP rank 1, EP rank 7, CP rank 3
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:21 [model_runner_v1.py:2618] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:21 [model_runner_v1.py:2618] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:21 [model_runner_v1.py:2618] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:21 [model_runner_v1.py:2618] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:21 [model_runner_v1.py:2618] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:21 [model_runner_v1.py:2618] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:21 [model_runner_v1.py:2618] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:21 [model_runner_v1.py:2618] Starting to load model /home/DeepSeek-V2-Lite...
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:21 [layer.py:845] [EP Rank 4/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->32, 1->33, 2->34, 3->35, 4->36, 5->37, 6->38, 7->39.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:21 [layer.py:845] [EP Rank 1/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->8, 1->9, 2->10, 3->11, 4->12, 5->13, 6->14, 7->15.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:21 [layer.py:845] [EP Rank 6/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->48, 1->49, 2->50, 3->51, 4->52, 5->53, 6->54, 7->55.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:21 [layer.py:845] [EP Rank 7/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->56, 1->57, 2->58, 3->59, 4->60, 5->61, 6->62, 7->63.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:21 [layer.py:845] [EP Rank 2/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->16, 1->17, 2->18, 3->19, 4->20, 5->21, 6->22, 7->23.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:22 [layer.py:845] [EP Rank 5/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->40, 1->41, 2->42, 3->43, 4->44, 5->45, 6->46, 7->47.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:22 [layer.py:845] [EP Rank 0/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->0, 1->1, 2->2, 3->3, 4->4, 5->5, 6->6, 7->7.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:22 [layer.py:845] [EP Rank 3/8] Expert parallelism is enabled. Local/global number of experts: 8/64. Experts local to global index map: 0->24, 1->25, 2->26, 3->27, 4->28, 5->29, 6->30, 7->31.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:37 [default_loader.py:267] Loading weights took 14.64 seconds
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:37 [default_loader.py:267] Loading weights took 14.43 seconds
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:37 [default_loader.py:267] Loading weights took 14.39 seconds
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:37 [default_loader.py:267] Loading weights took 14.45 seconds
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:37 [default_loader.py:267] Loading weights took 14.41 seconds
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:37 [default_loader.py:267] Loading weights took 14.41 seconds
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:37 [default_loader.py:267] Loading weights took 14.46 seconds
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:37 [default_loader.py:267] Loading weights took 14.44 seconds
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:38 [model_runner_v1.py:2648] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:38 [model_runner_v1.py:2648] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:38 [model_runner_v1.py:2648] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:38 [model_runner_v1.py:2648] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:38 [model_runner_v1.py:2648] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:38 [model_runner_v1.py:2648] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:38 [model_runner_v1.py:2648] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:38 [model_runner_v1.py:2648] Loading model weights took 5.3622 GB
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:43 [worker_v1.py:190] Available memory: 51937700659, total memory: 65796046848
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:43 [worker_v1.py:190] Available memory: 51673073664, total memory: 65787658240
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:43 [worker_v1.py:190] Available memory: 51929479987, total memory: 65796046848
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:44 [worker_v1.py:190] Available memory: 51942437683, total memory: 65796046848
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:44 [worker_v1.py:190] Available memory: 51935080243, total memory: 65796046848
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:44 [worker_v1.py:190] Available memory: 51672690688, total memory: 65787658240
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:44 [worker_v1.py:190] Available memory: 51680959488, total memory: 65787658240
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [worker_v1.py:190] Available memory: 51199168512, total memory: 65787658240
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:850] GPU KV cache size: 1,645,952 tokens
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3214.75x
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:850] GPU KV cache size: 1,669,632 tokens
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3261.00x
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:850] GPU KV cache size: 1,661,184 tokens
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3244.50x
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:850] GPU KV cache size: 1,669,760 tokens
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3261.25x
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:850] GPU KV cache size: 1,661,440 tokens
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3245.00x
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:850] GPU KV cache size: 1,669,504 tokens
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3260.75x
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:850] GPU KV cache size: 1,661,184 tokens
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3244.50x
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:850] GPU KV cache size: 1,669,888 tokens
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [kv_cache_utils.py:854] Maximum concurrency for 4,096 tokens per request: 3261.50x
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [core.py:217] init engine (profile, create kv cache, warmup model) took 5.67 seconds
[1;36m(EngineCore_0 pid=215225)[0;0m WARNING 09-10 17:14:44 [core.py:110] Using configured V1 scheduler class vllm_ascend.core.scheduler.AscendScheduler. This scheduler interface is not public and compatibility may not be maintained.
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [platform.py:144] Compilation disabled, using eager mode by default
[1;36m(EngineCore_0 pid=215225)[0;0m WARNING 09-10 17:14:44 [platform.py:162] compilation_config.level = CompilationLevel.NO_COMPILATION is set, Setting CUDAGraphMode to NONE
INFO 09-10 17:14:44 [llm.py:285] Supported_tasks: ['generate']
INFO 09-10 17:14:44 [__init__.py:36] No IOProcessor plugins requested by the model
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:44 [scheduler.py:179] ======> [SCH-PREFILL] req=0 chunk step_tokens=1024 cp=4 sp=2 num_blocks_of_cp_sp.shape=(4, 2) token_budget_left=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1105] =====> [MR-BLOCK-TABLE] req=0 first_blocks=[1, 2, 3, 4, 5, 6, 7, 8] block_size=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1114] =====> [MR-CP-SPLIT] req=0 cp_size=4 cp_base=256 cp_rem=0 per_step=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=2 sp=0 save_tokens_rank=256 kv_save_start=512
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1144] =====> [MR-SLOT-CHECK] req=0 kv_start=0 save_tokens_rank=256 slot_sample=[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=0 sp=0 save_tokens_rank=256 kv_save_start=0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=3 sp=0 save_tokens_rank=256 kv_save_start=768
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=0 sp=1 save_tokens_rank=256 kv_save_start=0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=2 sp=1 save_tokens_rank=256 kv_save_start=512
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=1 sp=1 save_tokens_rank=256 kv_save_start=256
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=1 sp=0 save_tokens_rank=256 kv_save_start=256
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=3 sp=1 save_tokens_rank=256 kv_save_start=768
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:44 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m WARNING 09-10 17:14:44 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m WARNING 09-10 17:14:44 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m WARNING 09-10 17:14:44 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m WARNING 09-10 17:14:44 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m WARNING 09-10 17:14:44 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m WARNING 09-10 17:14:44 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m WARNING 09-10 17:14:44 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m WARNING 09-10 17:14:44 [cudagraph_dispatcher.py:102] cudagraph dispatching keys are not initialized. No cudagraph will be used.
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:45 [scheduler.py:370] ======> [SCH-RUNNING] req=0 chunk step_tokens=122 cp=4 sp=2 num_blocks_of_cp_sp.shape=(4, 2) token_budget_left=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 122****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=0 sched_tokens=122 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=2 sp=0 save_tokens_rank=32 kv_save_start=64
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=3 sp=0 save_tokens_rank=32 kv_save_start=96
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=2 sp=1 save_tokens_rank=32 kv_save_start=64
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1105] =====> [MR-BLOCK-TABLE] req=0 first_blocks=[1, 2, 3, 4, 5, 6, 7, 8] block_size=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1114] =====> [MR-CP-SPLIT] req=0 cp_size=4 cp_base=32 cp_rem=0 per_step=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=1 sp=0 save_tokens_rank=32 kv_save_start=32
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1144] =====> [MR-SLOT-CHECK] req=0 kv_start=0 save_tokens_rank=32 slot_sample=[128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=3 sp=1 save_tokens_rank=32 kv_save_start=96
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=0 sp=0 save_tokens_rank=32 kv_save_start=0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=1 sp=1 save_tokens_rank=32 kv_save_start=32
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=0 sp=1 save_tokens_rank=32 kv_save_start=0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:45 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:46 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
TTFT: 2127.5343894958496 ms
req_num: 0
[['593', '595', '597', '599', '']] -> Generated text: '6 1 1 10 5'
Token ids: [21, 207, 16, 207, 16, 207, 16, 15, 207, 20]

[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:47 [scheduler.py:179] ======> [SCH-PREFILL] req=1 chunk step_tokens=1024 cp=4 sp=2 num_blocks_of_cp_sp.shape=(4, 2) token_budget_left=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1024****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1105] =====> [MR-BLOCK-TABLE] req=0 first_blocks=[10, 11, 12, 13, 14, 15, 16, 17] block_size=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1114] =====> [MR-CP-SPLIT] req=0 cp_size=4 cp_base=256 cp_rem=0 per_step=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=2 sp=0 save_tokens_rank=256 kv_save_start=512
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=1 sp=1 save_tokens_rank=256 kv_save_start=256
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=0 sp=1 save_tokens_rank=256 kv_save_start=0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=1024 cum_before=0 pos_cp.len=256 cp_pad_sched=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1144] =====> [MR-SLOT-CHECK] req=0 kv_start=0 save_tokens_rank=256 slot_sample=[1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=1 sp=0 save_tokens_rank=256 kv_save_start=256
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=0 sp=0 save_tokens_rank=256 kv_save_start=0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=3 sp=1 save_tokens_rank=256 kv_save_start=768
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=3 sp=0 save_tokens_rank=256 kv_save_start=768
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=2 sp=1 save_tokens_rank=256 kv_save_start=512
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[1024]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=128 q_tail_idx.len=128 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([128]) q_tail_idx.shape=torch.Size([128]) out_head.shape=torch.Size([128, 8, 128]) out_tail.shape=torch.Size([128, 8, 128]) out_concat.shape=torch.Size([256, 8, 128]) lse_head.shape=torch.Size([8, 128]) lse_tail.shape=torch.Size([8, 128])
[1;36m(EngineCore_0 pid=215225)[0;0m INFO 09-10 17:14:47 [scheduler.py:370] ======> [SCH-RUNNING] req=1 chunk step_tokens=126 cp=4 sp=2 num_blocks_of_cp_sp.shape=(4, 2) token_budget_left=1024
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 126****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 126****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 126****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 126****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 126****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 126****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 126****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 126****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=126 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=126 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=126 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=126 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=126 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=126 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=126 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1223] =====> [MR-PREFILL-CP] req=1 sched_tokens=126 cum_before=1024 pos_cp.len=32 cp_pad_sched=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1105] =====> [MR-BLOCK-TABLE] req=0 first_blocks=[10, 11, 12, 13, 14, 15, 16, 17] block_size=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=2 sp=0 save_tokens_rank=32 kv_save_start=64
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1114] =====> [MR-CP-SPLIT] req=0 cp_size=4 cp_base=32 cp_rem=0 per_step=128
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=2 sp=1 save_tokens_rank=32 kv_save_start=64
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=0 sp=1 save_tokens_rank=32 kv_save_start=0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=1 sp=1 save_tokens_rank=32 kv_save_start=32
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=1 sp=0 save_tokens_rank=32 kv_save_start=32
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1144] =====> [MR-SLOT-CHECK] req=0 kv_start=0 save_tokens_rank=32 slot_sample=[1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=0 sp=0 save_tokens_rank=32 kv_save_start=0
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=3 sp=0 save_tokens_rank=32 kv_save_start=96
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1149] =====> [MR-SLOT-RANK] req=0 cp=3 sp=1 save_tokens_rank=32 kv_save_start=96
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1329] =====> [MR-SLOT] PREFILL-CP slot_mapping.shape=(10240,) per_req_cp_pad_sched=[128]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1450] =====> [MR-LONG] chunk_seqlens.len=1 q_head_idx.len=16 q_tail_idx.len=16 attn_mask_seqlens.shape=torch.Size([2, 1]) head_nomask_seqlens.shape=torch.Size([2, 1]) tail_nomask_seqlens.shape=torch.Size([2, 1]) cp_mask.shape=torch.Size([512, 512])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [mla_v1.py:954] #####> [MLA-PREFILL-CP] q_head_idx.shape=torch.Size([16]) q_tail_idx.shape=torch.Size([16]) out_head.shape=torch.Size([16, 8, 128]) out_tail.shape=torch.Size([16, 8, 128]) out_concat.shape=torch.Size([32, 8, 128]) lse_head.shape=torch.Size([8, 16]) lse_tail.shape=torch.Size([8, 16])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:47 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1188] **** number of scheduled tokens: 1****
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1321] =====> [MR-PREFILL] cp=4 sp=2 num_reqs=1 query_lens.shape=torch.Size([1]) seq_lens.shape=torch.Size([1])
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215247)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215252)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215232)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215242)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215257)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP0 pid=215262)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215267)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
[1;36m(EngineCore_0 pid=215225)[0;0m [1;36m(VllmWorker TP1 pid=215237)[0;0m INFO 09-10 17:14:48 [model_runner_v1.py:1335] =====> [MR-SLOT] DECODE-CP slot_mapping.shape=(10240,) per_req_sched=[1]
TTFT: 1523.8971710205078 ms
req_num: 0
[['595', '597', '599', '601', '']] -> Generated text: '609 603 60'
Token ids: [21, 15, 24, 207, 21, 15, 18, 207, 21, 15]

end.
ERROR 09-10 17:14:50 [core_client.py:562] Engine core proc EngineCore_0 died unexpectedly, shutting down client.
